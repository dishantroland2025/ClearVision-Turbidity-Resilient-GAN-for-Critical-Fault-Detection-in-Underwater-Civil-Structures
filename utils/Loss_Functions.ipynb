{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUvwH4T6dHHW",
        "outputId": "5606d286-179e-41cd-b88e-a7e23dc0be04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ClearVision-Turbidity-Resilient-GAN-for-Critical-Fault-Detection-in-Underwater-Civil-Structures'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 0 (delta 0), pack-reused 52 (from 1)\u001b[K\n",
            "Receiving objects: 100% (52/52), 139.15 MiB | 46.89 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dishantroland2025/ClearVision-Turbidity-Resilient-GAN-for-Critical-Fault-Detection-in-Underwater-Civil-Structures.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import kornia.color as K\n",
        "import kornia.filters as KF\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Adversarial Loss (LSGAN)\n",
        "# -------------------------------------------------\n",
        "def adversarial_loss(pred, target_is_real=True):\n",
        "    target = torch.ones_like(pred) if target_is_real else torch.zeros_like(pred)\n",
        "    return torch.mean((pred - target) ** 2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Pixel Loss (L1)\n",
        "# -------------------------------------------------\n",
        "def pixel_loss(fake, real):\n",
        "    return torch.mean(torch.abs(fake - real))\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# LAB Color Loss (a, b channels only)\n",
        "# -------------------------------------------------\n",
        "def lab_color_loss(fake, real):\n",
        "    fake_lab = K.rgb_to_lab((fake + 1) / 2)\n",
        "    real_lab = K.rgb_to_lab((real + 1) / 2)\n",
        "\n",
        "    # Only a and b channels\n",
        "    return (\n",
        "        torch.mean(torch.abs(fake_lab[:, 1] - real_lab[:, 1])) +\n",
        "        torch.mean(torch.abs(fake_lab[:, 2] - real_lab[:, 2]))\n",
        "    )\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Edge Loss (Sobel)\n",
        "# -------------------------------------------------\n",
        "def edge_loss(fake, real):\n",
        "    fake_edges = KF.sobel(fake)\n",
        "    real_edges = KF.sobel(real)\n",
        "    return torch.mean(torch.abs(fake_edges - real_edges))\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Depth-Weighted Loss (ADDED)\n",
        "# -------------------------------------------------\n",
        "def depth_weighted_loss(fake, real, depth, max_depth=1.0):\n",
        "    \"\"\"\n",
        "    Emphasizes distant / heavily degraded regions.\n",
        "    depth: (B, 1, H, W) or (B, H, W)\n",
        "    \"\"\"\n",
        "    if depth.dim() == 3:\n",
        "        depth = depth.unsqueeze(1)\n",
        "\n",
        "    weights = 1.0 + 4.0 * (depth / max_depth)\n",
        "    return torch.mean(weights * torch.abs(fake - real))\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Perceptual Loss (VGG-based)\n",
        "# -------------------------------------------------\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self, vgg):\n",
        "        super().__init__()\n",
        "        self.vgg = vgg\n",
        "        self.layers = [2, 7, 16, 25]  # relu1_2, relu2_2, relu3_4, relu4_4\n",
        "\n",
        "    def forward(self, fake, real):\n",
        "        loss = torch.tensor(0.0, device=fake.device)\n",
        "        x_f, x_r = fake, real\n",
        "\n",
        "        for i, layer in enumerate(self.vgg):\n",
        "            x_f = layer(x_f)\n",
        "            x_r = layer(x_r)\n",
        "            if i in self.layers:\n",
        "                loss += torch.mean(torch.abs(x_f - x_r))\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Generator Loss (Combined)\n",
        "# -------------------------------------------------\n",
        "def generator_loss(\n",
        "    D,\n",
        "    real_img,\n",
        "    fake_img,\n",
        "    input_img,\n",
        "    depth=None,\n",
        "    max_depth=1.0,\n",
        "    perceptual_fn=None,\n",
        "    lambdas=None\n",
        "):\n",
        "    # Adversarial\n",
        "    pred_fake = D(input_img, fake_img)\n",
        "    loss_adv = adversarial_loss(pred_fake, True)\n",
        "\n",
        "    # Core losses\n",
        "    loss_pix = pixel_loss(fake_img, real_img)\n",
        "    loss_color = lab_color_loss(fake_img, real_img)\n",
        "    loss_edge = edge_loss(fake_img, real_img)\n",
        "    loss_perc = perceptual_fn(fake_img, real_img) if perceptual_fn is not None else 0\n",
        "\n",
        "    # Depth (optional)\n",
        "    loss_depth = (\n",
        "        depth_weighted_loss(fake_img, real_img, depth, max_depth)\n",
        "        if depth is not None else 0\n",
        "    )\n",
        "\n",
        "    # Weighted sum\n",
        "    total = (\n",
        "        lambdas[\"adv\"] * loss_adv +\n",
        "        lambdas[\"pixel\"] * loss_pix +\n",
        "        lambdas[\"color\"] * loss_color +\n",
        "        lambdas[\"edge\"] * loss_edge +\n",
        "        lambdas[\"perc\"] * loss_perc +\n",
        "        lambdas[\"depth\"] * loss_depth\n",
        "    )\n",
        "\n",
        "    return total\n"
      ],
      "metadata": {
        "id": "c-Ox_euTxVOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7yTM2mnxVRW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}